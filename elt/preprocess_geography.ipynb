{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shapefile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import us\n",
    "from itertools import combinations\n",
    "import haversine\n",
    "import json\n",
    "from shapely.geometry import shape as shapely\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Congressional District Geography\n",
    "This notebook will:\n",
    "1. Calculate the distance between every congressional district going back to 102.\n",
    "2. Determine if districts are neighbors\n",
    "3. Convert the shape file to geojson for ease of use with D3.\n",
    "4. Calculate distances between state centroids (for senators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_coordinates(row):\n",
    "    \"\"\"Fill district bounding box and place in format accepted by shapely\"\"\"\n",
    "    points = []\n",
    "    points.append((row.bbox0, row.bbox1))\n",
    "    points.append((row.bbox0, row.bbox3))\n",
    "    points.append((row.bbox2, row.bbox3))\n",
    "    points.append((row.bbox2, row.bbox1))\n",
    "    return {'coordinates':[points], 'type': 'Polygon'}\n",
    "\n",
    "df_members = pd.read_csv('../propublica/members_house.csv')\n",
    "df_members = df_members[['id','session','state','district']]\n",
    "df_members['district'] = df_members.district.replace({'At-Large': 0})\n",
    "df_members['dist_full'] = df_members.apply(lambda x: x.state + \"_\" + str(x.district), axis=1)\n",
    "df_members.drop(['state', 'district'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steve\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n",
      "112\n",
      "111\n",
      "110\n",
      "109\n",
      "108\n",
      "107\n",
      "106\n",
      "105\n",
      "104\n",
      "103\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "for congress in reversed(range(102,115)):\n",
    "#for congress in reversed(range(114,115)):\n",
    "    print(congress)\n",
    "    # load shape file\n",
    "    file_loc = 'districts' + str(congress)\n",
    "    file_loc += (\"/\" + file_loc + \".shp\")\n",
    "    districts = shapefile.Reader('shapefiles/' + file_loc)\n",
    "    \n",
    "    # get bounding box and centroid of districts\n",
    "    rows = []\n",
    "    shapes = districts.shapes()\n",
    "    records = districts.records()\n",
    "    i = 0\n",
    "    for shape, record in zip(shapes, records):\n",
    "        bbox = {}\n",
    "        for b in range(0,4):\n",
    "            try:\n",
    "                bbox[b] = shape.bbox[b]\n",
    "            except:\n",
    "                bbox[b] = np.nan\n",
    "\n",
    "        lat = (bbox[1] + bbox[3])/ 2\n",
    "        lon = (bbox[0] + bbox[2])/ 2\n",
    "\n",
    "        row = {'state': record[0], \n",
    "               'district': record[2], \n",
    "               'lat': lat, \n",
    "               'lon': lon, \n",
    "               'bbox0': bbox[0],\n",
    "               'bbox1': bbox[1],\n",
    "               'bbox2': bbox[2],\n",
    "               'bbox3': bbox[3], \n",
    "               'i':i}\n",
    "        rows.append(row)\n",
    "        i += 1\n",
    "    \n",
    "    # convert district info to df\n",
    "    df_districts = pd.DataFrame(rows)\n",
    "    df_districts.dropna(inplace=True)\n",
    "    cw = us.states.mapping('name','abbr')\n",
    "    df_districts['state_abbr'] = df_districts.state.replace(cw)\n",
    "    df_districts['dist_full'] = df_districts.apply(lambda x: x.state_abbr + \"_\" + str(x.district), axis=1)\n",
    "    df_districts['coords'] = df_districts.apply(lambda x: tuple([x.lat, x.lon]), axis=1)\n",
    "    \n",
    "    # calculate distances between all districts\n",
    "    # and if districts touch\n",
    "    distances = []\n",
    "    for d1,d2 in combinations(df_districts.dist_full.unique(), 2):\n",
    "        d1_coord = df_districts[df_districts.dist_full == d1].coords.iloc[0]\n",
    "        d1_shape = shapely(construct_coordinates(df_districts[df_districts.dist_full == d1].iloc[0]))\n",
    "        d2_coord = df_districts[df_districts.dist_full == d2].coords.iloc[0]\n",
    "        d2_shape = shapely(construct_coordinates(df_districts[df_districts.dist_full == d2].iloc[0]))\n",
    "\n",
    "        distance = haversine.haversine(d1_coord, d2_coord, miles = True)\n",
    "        if d1_shape.touches(d2_shape):\n",
    "            neighbor = 1\n",
    "        elif d1_shape.intersects(d2_shape):\n",
    "            neighbor = 1\n",
    "        else:\n",
    "            neighbor = 0\n",
    "\n",
    "        row = {'d1':d1,'d2':d2, 'distance': distance, 'neighbor': neighbor}\n",
    "        distances.append(row)\n",
    "        \n",
    "    # for ease of future lookup, \n",
    "    # duplicate df, switch d1 and d2 columns, and concat\n",
    "    df_distances = pd.DataFrame(distances)\n",
    "    df_distances = pd.concat([df_distances, df_distances.rename(columns={'d1':'d2','d2':'d1'})])\n",
    "    df_distances = pd.merge(df_distances, \n",
    "                            df_districts, \n",
    "                            how = 'left', \n",
    "                            left_on='d1', \n",
    "                            right_on = 'dist_full')\n",
    "    df_distances = pd.merge(df_distances, \n",
    "                            df_districts, \n",
    "                            how = 'left', \n",
    "                            left_on='d2', \n",
    "                            right_on = 'dist_full', \n",
    "                            suffixes=['_d1','_d2'])\n",
    "    df_distances['congress'] = congress\n",
    "\n",
    "    # merge in propublica member id\n",
    "    df_congress = df_members[df_members.session == congress]\n",
    "    df_congress.drop(['session'], axis = 1, inplace=True)\n",
    "    df_distances = pd.merge(df_distances, df_congress.rename(columns={'dist_full': 'd1'}), how = 'left', on='d1')\n",
    "    df_distances = pd.merge(df_distances, \n",
    "                    df_congress.rename(columns={'dist_full': 'd2'}), \n",
    "                    how = 'left', \n",
    "                    on='d2', suffixes=['_d1','_d2'])\n",
    "\n",
    "    df_distances.to_csv('geo_preprocessed/geo_' + str(congress) + '.csv', index = False)\n",
    "\n",
    "    # convert shape file to geojson and export\n",
    "    fields = districts.fields[1:]\n",
    "    field_names = [field[0] for field in fields]\n",
    "    buffer = []\n",
    "    for sr in districts.shapeRecords():\n",
    "        atr = dict(zip(field_names, sr.record))\n",
    "        geom = sr.shape.__geo_interface__\n",
    "        buffer.append(dict(type=\"Feature\", \\\n",
    "        geometry=geom, properties=atr)) \n",
    "    geojson = open('geojson/congress_' + str(congress) + '.json', \"w\")\n",
    "    geojson.write(json.dumps({\"type\": \"FeatureCollection\",\"features\": buffer}, indent=2) + \"\\n\")\n",
    "    geojson.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_states = pd.read_csv('state_geo.csv', encoding = 'latin1', index_col='state_abbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>neighbors</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_abbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>12.1 mi (19.5 km) southwest of Clanton</td>\n",
       "      <td>32.7794°N 86.8287°W</td>\n",
       "      <td>32.7794</td>\n",
       "      <td>-86.8287</td>\n",
       "      <td>['FL', 'GA', 'MS', 'TN']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>77.9 mi (125.4 km) northwest of Denali</td>\n",
       "      <td>64.0685°N 152.2782°W</td>\n",
       "      <td>64.0685</td>\n",
       "      <td>-152.2782</td>\n",
       "      <td>['WA']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>49.7 mi (80.0 km) east-southeast of Prescott</td>\n",
       "      <td>34.2744°N 111.6602°W</td>\n",
       "      <td>34.2744</td>\n",
       "      <td>-111.6602</td>\n",
       "      <td>['CA', 'CO', 'NM', 'NV', 'UT']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>14.2 mi (22.9 km) northwest of Little Rock</td>\n",
       "      <td>34.8938°N 92.4426°W</td>\n",
       "      <td>34.8938</td>\n",
       "      <td>-92.4426</td>\n",
       "      <td>['LA', 'MO', 'MS', 'OK', 'TN', 'TX']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>California</td>\n",
       "      <td>36 mi (58 km) northeast of Madera,</td>\n",
       "      <td>37.1841°N 119.4696°W</td>\n",
       "      <td>37.1841</td>\n",
       "      <td>-119.4696</td>\n",
       "      <td>['HI', 'NV', 'OR', 'AZ']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 State                                       Location  \\\n",
       "state_abbr                                                              \n",
       "AL             Alabama        12.1 mi (19.5 km) southwest of Clanton    \n",
       "AK              Alaska        77.9 mi (125.4 km) northwest of Denali    \n",
       "AZ             Arizona  49.7 mi (80.0 km) east-southeast of Prescott    \n",
       "AR            Arkansas    14.2 mi (22.9 km) northwest of Little Rock    \n",
       "CA          California            36 mi (58 km) northeast of Madera,    \n",
       "\n",
       "                     Coordinates      lat       lon  \\\n",
       "state_abbr                                            \n",
       "AL           32.7794°N 86.8287°W  32.7794  -86.8287   \n",
       "AK          64.0685°N 152.2782°W  64.0685 -152.2782   \n",
       "AZ          34.2744°N 111.6602°W  34.2744 -111.6602   \n",
       "AR           34.8938°N 92.4426°W  34.8938  -92.4426   \n",
       "CA          37.1841°N 119.4696°W  37.1841 -119.4696   \n",
       "\n",
       "                                       neighbors  \n",
       "state_abbr                                        \n",
       "AL                      ['FL', 'GA', 'MS', 'TN']  \n",
       "AK                                        ['WA']  \n",
       "AZ                ['CA', 'CO', 'NM', 'NV', 'UT']  \n",
       "AR          ['LA', 'MO', 'MS', 'OK', 'TN', 'TX']  \n",
       "CA                      ['HI', 'NV', 'OR', 'AZ']  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "for state1, row1 in df_states.iterrows():\n",
    "    for state2, row2 in df_states.iterrows():\n",
    "        new_row = {'state1': state1, 'state2':state2, 'touching': False}\n",
    "        coords1 = (row1.lat, row1.lon)\n",
    "        coords2 = (row2.lat, row2.lon)\n",
    "        distance = haversine.haversine(coords1, coords2, miles=True)\n",
    "        new_row['distance'] = distance\n",
    "        if state2 in eval(row1.neighbors):\n",
    "            new_row['touching'] = True\n",
    "        output.append(new_row)\n",
    "pd.DataFrame(output).to_csv('state_distances.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cw = us.states.mapping('name','abbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_state_divs = pd.read_csv('state_divisions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_states = pd.merge(df_states, df_state_divs, how = 'left', left_on='State', right_on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_states.to_csv('state_geo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Division</th>\n",
       "      <th>State\n",
       "(FIPS)</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Northeast Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>New England Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Connecticut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>Maine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>Massachusetts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Region  Division  State\\n(FIPS)                  Name\n",
       "0       1         0              0      Northeast Region\n",
       "1       1         1              0  New England Division\n",
       "2       1         1              9           Connecticut\n",
       "3       1         1             23                 Maine\n",
       "4       1         1             25         Massachusetts"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_state_divs.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
