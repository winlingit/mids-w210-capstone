{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shapefile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import us\n",
    "from itertools import combinations\n",
    "import haversine\n",
    "import json\n",
    "from shapely.geometry import shape as shapely\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Congressional District Geography\n",
    "This notebook will:\n",
    "1. Calculate the distance between every congressional district going back to 102.\n",
    "2. Determine if districts are neighbors\n",
    "3. Convert the shape file to geojson for ease of use with D3.\n",
    "4. Calculate distances between state centroids (for senators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_coordinates(row):\n",
    "    \"\"\"Fill district bounding box and place in format accepted by shapely\"\"\"\n",
    "    points = []\n",
    "    points.append((row.bbox0, row.bbox1))\n",
    "    points.append((row.bbox0, row.bbox3))\n",
    "    points.append((row.bbox2, row.bbox3))\n",
    "    points.append((row.bbox2, row.bbox1))\n",
    "    return {'coordinates':[points], 'type': 'Polygon'}\n",
    "\n",
    "df_members = pd.read_csv('../propublica/members_house.csv')\n",
    "df_members = df_members[['id','session','state','district']]\n",
    "df_members['district'] = df_members.district.replace({'At-Large': 0})\n",
    "df_members['dist_full'] = df_members.apply(lambda x: x.state + \"_\" + str(x.district), axis=1)\n",
    "df_members.drop(['state', 'district'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steve\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n",
      "112\n",
      "111\n",
      "110\n",
      "109\n",
      "108\n",
      "107\n",
      "106\n",
      "105\n",
      "104\n",
      "103\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "for congress in reversed(range(102,115)):\n",
    "#for congress in reversed(range(114,115)):\n",
    "    print(congress)\n",
    "    # load shape file\n",
    "    file_loc = 'districts' + str(congress)\n",
    "    file_loc += (\"/\" + file_loc + \".shp\")\n",
    "    districts = shapefile.Reader('shapefiles/' + file_loc)\n",
    "    \n",
    "    # get bounding box and centroid of districts\n",
    "    rows = []\n",
    "    shapes = districts.shapes()\n",
    "    records = districts.records()\n",
    "    i = 0\n",
    "    for shape, record in zip(shapes, records):\n",
    "        bbox = {}\n",
    "        for b in range(0,4):\n",
    "            try:\n",
    "                bbox[b] = shape.bbox[b]\n",
    "            except:\n",
    "                bbox[b] = np.nan\n",
    "\n",
    "        lat = (bbox[1] + bbox[3])/ 2\n",
    "        lon = (bbox[0] + bbox[2])/ 2\n",
    "\n",
    "        row = {'state': record[0], \n",
    "               'district': record[2], \n",
    "               'lat': lat, \n",
    "               'lon': lon, \n",
    "               'bbox0': bbox[0],\n",
    "               'bbox1': bbox[1],\n",
    "               'bbox2': bbox[2],\n",
    "               'bbox3': bbox[3], \n",
    "               'i':i}\n",
    "        rows.append(row)\n",
    "        i += 1\n",
    "    \n",
    "    # convert district info to df\n",
    "    df_districts = pd.DataFrame(rows)\n",
    "    df_districts.dropna(inplace=True)\n",
    "    cw = us.states.mapping('name','abbr')\n",
    "    df_districts['state_abbr'] = df_districts.state.replace(cw)\n",
    "    df_districts['dist_full'] = df_districts.apply(lambda x: x.state_abbr + \"_\" + str(x.district), axis=1)\n",
    "    df_districts['coords'] = df_districts.apply(lambda x: tuple([x.lat, x.lon]), axis=1)\n",
    "    \n",
    "    # calculate distances between all districts\n",
    "    # and if districts touch\n",
    "    distances = []\n",
    "    for d1,d2 in combinations(df_districts.dist_full.unique(), 2):\n",
    "        d1_coord = df_districts[df_districts.dist_full == d1].coords.iloc[0]\n",
    "        d1_shape = shapely(construct_coordinates(df_districts[df_districts.dist_full == d1].iloc[0]))\n",
    "        d2_coord = df_districts[df_districts.dist_full == d2].coords.iloc[0]\n",
    "        d2_shape = shapely(construct_coordinates(df_districts[df_districts.dist_full == d2].iloc[0]))\n",
    "\n",
    "        distance = haversine.haversine(d1_coord, d2_coord, miles = True)\n",
    "        if d1_shape.touches(d2_shape):\n",
    "            neighbor = 1\n",
    "        elif d1_shape.intersects(d2_shape):\n",
    "            neighbor = 1\n",
    "        else:\n",
    "            neighbor = 0\n",
    "\n",
    "        row = {'d1':d1,'d2':d2, 'distance': distance, 'neighbor': neighbor}\n",
    "        distances.append(row)\n",
    "        \n",
    "    # for ease of future lookup, \n",
    "    # duplicate df, switch d1 and d2 columns, and concat\n",
    "    df_distances = pd.DataFrame(distances)\n",
    "    df_distances = pd.concat([df_distances, df_distances.rename(columns={'d1':'d2','d2':'d1'})])\n",
    "    df_distances = pd.merge(df_distances, \n",
    "                            df_districts, \n",
    "                            how = 'left', \n",
    "                            left_on='d1', \n",
    "                            right_on = 'dist_full')\n",
    "    df_distances = pd.merge(df_distances, \n",
    "                            df_districts, \n",
    "                            how = 'left', \n",
    "                            left_on='d2', \n",
    "                            right_on = 'dist_full', \n",
    "                            suffixes=['_d1','_d2'])\n",
    "    df_distances['congress'] = congress\n",
    "\n",
    "    # merge in propublica member id\n",
    "    df_congress = df_members[df_members.session == congress]\n",
    "    df_congress.drop(['session'], axis = 1, inplace=True)\n",
    "    df_distances = pd.merge(df_distances, df_congress.rename(columns={'dist_full': 'd1'}), how = 'left', on='d1')\n",
    "    df_distances = pd.merge(df_distances, \n",
    "                    df_congress.rename(columns={'dist_full': 'd2'}), \n",
    "                    how = 'left', \n",
    "                    on='d2', suffixes=['_d1','_d2'])\n",
    "\n",
    "    df_distances.to_csv('geo_preprocessed/geo_' + str(congress) + '.csv', index = False)\n",
    "\n",
    "    # convert shape file to geojson and export\n",
    "    fields = districts.fields[1:]\n",
    "    field_names = [field[0] for field in fields]\n",
    "    buffer = []\n",
    "    for sr in districts.shapeRecords():\n",
    "        atr = dict(zip(field_names, sr.record))\n",
    "        geom = sr.shape.__geo_interface__\n",
    "        buffer.append(dict(type=\"Feature\", \\\n",
    "        geometry=geom, properties=atr)) \n",
    "    geojson = open('geojson/congress_' + str(congress) + '.json', \"w\")\n",
    "    geojson.write(json.dumps({\"type\": \"FeatureCollection\",\"features\": buffer}, indent=2) + \"\\n\")\n",
    "    geojson.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_states = pd.read_csv('state_geo.csv', encoding = 'latin1', index_col='state_abbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>neighbors</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_abbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>12.1 mi (19.5 km) southwest of Clanton</td>\n",
       "      <td>32.7794째N 86.8287째W</td>\n",
       "      <td>32.7794</td>\n",
       "      <td>-86.8287</td>\n",
       "      <td>['FL', 'GA', 'MS', 'TN']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>77.9 mi (125.4 km) northwest of Denali</td>\n",
       "      <td>64.0685째N 152.2782째W</td>\n",
       "      <td>64.0685</td>\n",
       "      <td>-152.2782</td>\n",
       "      <td>['WA']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>49.7 mi (80.0 km) east-southeast of Prescott</td>\n",
       "      <td>34.2744째N 111.6602째W</td>\n",
       "      <td>34.2744</td>\n",
       "      <td>-111.6602</td>\n",
       "      <td>['CA', 'CO', 'NM', 'NV', 'UT']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>14.2 mi (22.9 km) northwest of Little Rock</td>\n",
       "      <td>34.8938째N 92.4426째W</td>\n",
       "      <td>34.8938</td>\n",
       "      <td>-92.4426</td>\n",
       "      <td>['LA', 'MO', 'MS', 'OK', 'TN', 'TX']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>California</td>\n",
       "      <td>36 mi (58 km) northeast of Madera,</td>\n",
       "      <td>37.1841째N 119.4696째W</td>\n",
       "      <td>37.1841</td>\n",
       "      <td>-119.4696</td>\n",
       "      <td>['HI', 'NV', 'OR', 'AZ']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 State                                       Location  \\\n",
       "state_abbr                                                              \n",
       "AL             Alabama        12.1 mi (19.5 km) southwest of Clanton    \n",
       "AK              Alaska        77.9 mi (125.4 km) northwest of Denali    \n",
       "AZ             Arizona  49.7 mi (80.0 km) east-southeast of Prescott    \n",
       "AR            Arkansas    14.2 mi (22.9 km) northwest of Little Rock    \n",
       "CA          California            36 mi (58 km) northeast of Madera,    \n",
       "\n",
       "                     Coordinates      lat       lon  \\\n",
       "state_abbr                                            \n",
       "AL           32.7794째N 86.8287째W  32.7794  -86.8287   \n",
       "AK          64.0685째N 152.2782째W  64.0685 -152.2782   \n",
       "AZ          34.2744째N 111.6602째W  34.2744 -111.6602   \n",
       "AR           34.8938째N 92.4426째W  34.8938  -92.4426   \n",
       "CA          37.1841째N 119.4696째W  37.1841 -119.4696   \n",
       "\n",
       "                                       neighbors  \n",
       "state_abbr                                        \n",
       "AL                      ['FL', 'GA', 'MS', 'TN']  \n",
       "AK                                        ['WA']  \n",
       "AZ                ['CA', 'CO', 'NM', 'NV', 'UT']  \n",
       "AR          ['LA', 'MO', 'MS', 'OK', 'TN', 'TX']  \n",
       "CA                      ['HI', 'NV', 'OR', 'AZ']  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "for state1, row1 in df_states.iterrows():\n",
    "    for state2, row2 in df_states.iterrows():\n",
    "        new_row = {'state1': state1, 'state2':state2, 'touching': False}\n",
    "        coords1 = (row1.lat, row1.lon)\n",
    "        coords2 = (row2.lat, row2.lon)\n",
    "        distance = haversine.haversine(coords1, coords2, miles=True)\n",
    "        new_row['distance'] = distance\n",
    "        if state2 in eval(row1.neighbors):\n",
    "            new_row['touching'] = True\n",
    "        output.append(new_row)\n",
    "pd.DataFrame(output).to_csv('state_distances.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cw = us.states.mapping('name','abbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_state_divs = pd.read_csv('state_divisions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_states = pd.merge(df_states, df_state_divs, how = 'left', left_on='State', right_on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_states.to_csv('state_geo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Division</th>\n",
       "      <th>State\n",
       "(FIPS)</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Northeast Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>New England Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Connecticut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>Maine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>Massachusetts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Region  Division  State\\n(FIPS)                  Name\n",
       "0       1         0              0      Northeast Region\n",
       "1       1         1              0  New England Division\n",
       "2       1         1              9           Connecticut\n",
       "3       1         1             23                 Maine\n",
       "4       1         1             25         Massachusetts"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_state_divs.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
